name: Simple ETL Pipeline V2

on:
  push:
    branches:
      - main

jobs:
  etl-job:
    runs-on: ubuntu-latest
  
    services:
        postgres:
          image: postgres:15
          env:
            POSTGRES_USER: postgres
            POSTGRES_PASSWORD: postgres
            POSTGRES_DB: etl_db
          ports:
            - 5432:5432
          options: >-
            --health-cmd="pg_isready -U postgres"
            --health-interval=10s
            --health-timeout=5s
            --health-retries=5

    strategy:
      matrix:
        python-version: [3.8, 3.9]

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Run ETL Script
        run: |
          python python_script.py

      - name: Install PostgreSQL client
        run: sudo apt-get update && sudo apt-get install -y postgresql-client

      - name: Create table in Postgres
        run: |
          PGPASSWORD=postgres psql -h localhost -U postgres -d etl_db -c "
          CREATE TABLE IF NOT EXISTS transformed_employees (
            employee_id INT,
            first_name TEXT,
            department TEXT,
            salary NUMERIC,
            employment_type TEXT,
            tax NUMERIC,
            net_salary NUMERIC
          );"

      - name: Load CSV into Postgres
        run: |
          PGPASSWORD=postgres psql -h localhost -U postgres -d etl_db -c "\copy transformed_employees FROM 'transformed_employees.csv' DELIMITER ',' CSV HEADER;"

      - name: Create dbt profile
        run: |
          mkdir -p ~/.dbt
          echo "
          simple_etl:
            target: dev
            outputs:
              dev:
                type: postgres
                host: localhost
                user: postgres
                password: postgres
                port: 5432
                dbname: etl_db
                schema: public
          " > ~/.dbt/profiles.yml
      
      - name: Run dbt models
        run: dbt run

      - name: Run dbt tests
        run: dbt test

      - name: Upload transformed file
        uses: actions/upload-artifact@v4
        with:
          name: transformed-data-${{ matrix.python-version }}
          path: transformed_employees.csv

  verify-artifact:
    needs: etl-job
    runs-on: ubuntu-latest

    steps:
      - name: Download artifact (Python 3.8)
        uses: actions/download-artifact@v4
        with:
          name: transformed-data-3.8
          path: ./downloaded

      - name: Show downloaded file
        run: |
          ls -l ./downloaded
          cat ./downloaded/transformed_employees.csv